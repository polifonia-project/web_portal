{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "polifonia_web_portal_report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arp_gmKiGiYH"
      },
      "source": [
        "# Polifonia web portal data layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qvXFGYvGn0T"
      },
      "source": [
        "## Imports and data parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMivAaFcjWH"
      },
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "q7E4dnf_COtI",
        "outputId": "9ba3108f-7ebd-48df-cfbc-55e0ea643987"
      },
      "source": [
        "# Parse google spreadsheet\n",
        "\n",
        "# authenticate\n",
        "auth.authenticate_user()\n",
        "\n",
        "# spreadsheet: Research topics\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "spreadsheet = gc.open('Polifonia_web_portal_CQ')\n",
        "topics = spreadsheet.get_worksheet(1)\n",
        "\n",
        "# Transform tables to dataframes. \n",
        "\n",
        "def make_header(df):\n",
        "  new_header = df.iloc[0] \n",
        "  df = df[1:] \n",
        "  df.columns = new_header\n",
        "  return df\n",
        "\n",
        "# CQs\n",
        "rows = topics.get_all_values()\n",
        "df = pd.DataFrame.from_records(rows)\n",
        "df = make_header(df)\n",
        "\n",
        "persona = [re.split('\\d+',values)[0] for values in df['CQ ID']]    \n",
        "df[\"persona\"] = persona\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-56a0153daeb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# authenticate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# spreadsheet: Research topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGFJVgi8Gy5B"
      },
      "source": [
        "## Overview \n",
        "\n",
        " - CQ classification\n",
        " - CQ addressing only main entities/properties\n",
        " - Personas coverage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deOwVyQvCvsQ",
        "outputId": "59f55c16-6d42-4af7-9a6e-1296a14a5837"
      },
      "source": [
        "all = len(df)\n",
        "biblio_data = len(df[df[\"Bibl. \\ndata\"] == 'yes'])\n",
        "music_data = len(df[df[\"Music \\ndata\"] == 'yes'])\n",
        "ling_data = len(df[df[\"Linguistic data\"] == 'yes'])\n",
        "\n",
        "biblio_data_only = len(df[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Music \\ndata\"] == 'no') & (df[\"Linguistic data\"] == 'no')])\n",
        "music_data_only = len(df[(df[\"Music \\ndata\"] == 'yes') & (df[\"Bibl. \\ndata\"] == 'no') & (df[\"Linguistic data\"] == 'no')])\n",
        "ling_data_only = len(df[(df[\"Linguistic data\"] == 'yes') & (df[\"Music \\ndata\"] == 'no') & (df[\"Bibl. \\ndata\"] == 'no')])\n",
        "\n",
        "biblio_ling = len(df[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Linguistic data\"] == 'yes')])\n",
        "biblio_music = len(df[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Music \\ndata\"] == 'yes')])\n",
        "biblio_music_ling = len(df[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Music \\ndata\"] == 'yes')& (df[\"Linguistic data\"] == 'yes')])\n",
        "\n",
        "music_ling = len(df[(df[\"Music \\ndata\"] == 'yes')& (df[\"Linguistic data\"] == 'yes')])\n",
        "others = len(df[(df[\"Bibl. \\ndata\"] == 'no') & (df[\"Music \\ndata\"] == 'no')& (df[\"Linguistic data\"] == 'no')])\n",
        "\n",
        "print(\"Total\",all,\\\n",
        "      \"\\n - Bibliographic\",biblio_data, \"(bibl. only\",biblio_data_only,\"; linguistic\",biblio_ling,\"; music\",biblio_music,\"; both\", biblio_music_ling,\")\"\\\n",
        "      \"\\n - Music\",music_data, \"(music only\",music_data_only,\"; bibliographic\",biblio_music,\"; music\",music_ling ,\"; both\", biblio_music_ling,\")\"\\\n",
        "      \"\\n - Linguistic\",ling_data, \"(ling only\",ling_data_only,\"; bibliographic\",biblio_ling,\"; music\",music_ling ,\"; both\", biblio_music_ling,\")\"\\\n",
        "      \"\\n - Other\",others)\n",
        "\n",
        "to_include = df[df[\"Include\\nin portal?\"] == 'yes']\n",
        "to_include_bibl = len(to_include[to_include[\"Bibl. \\ndata\"] == 'yes'])\n",
        "to_include_music = len(to_include[to_include[\"Music \\ndata\"] == 'yes'])\n",
        "to_include_ling = len(to_include[to_include[\"Linguistic data\"] == 'yes'])\n",
        "\n",
        "print(\"\\nTo be included in indexes (based on web portal data layer)\", len(to_include), \"(\",len(to_include)*100/all,\"%)\"\\\n",
        "      \"\\n - Bibliographic\",to_include_bibl,\\\n",
        "      \"\\n - Music\", to_include_music,\\\n",
        "      \"\\n - Linguistic\",to_include_ling)\n",
        "\n",
        "pf = to_include\n",
        "pf_persona = pf.groupby(\"persona\")[\"CQ ID\"].count()\n",
        "df_persona = df.groupby(\"persona\")[\"CQ ID\"].count()\n",
        "personas = pd.merge(pf_persona, df_persona, on=\"persona\")\n",
        "personas.reset_index(level=0, inplace=True)\n",
        "personas[\"percentage\"] = (personas[\"CQ ID_x\"].astype(int)*100/personas[\"CQ ID_y\"].astype(int)).apply(lambda x: f\"{x:.2f}\")\n",
        "personas['_'] = personas[['persona', 'percentage']].apply(tuple, axis=1)\n",
        "\n",
        "print(\"\\nPersonas covered in indexes\")\n",
        "for p,c in personas['_']:\n",
        "  print(\" - \",p,c,\"%\")\n",
        "\n",
        "pf_list = pf_persona.index.tolist()\n",
        "df_list = df_persona.index.tolist()\n",
        "diff = list(set(df_list) - set(pf_list))\n",
        "\n",
        "print(\"\\nPersonas not covered in indexes:\\n -\", \"\\n - \".join(diff))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 217 \n",
            " - Bibliographic 156 (bibl. only 81 ; linguistic 62 ; music 23 ; both 10 )\n",
            " - Music 66 (music only 38 ; bibliographic 23 ; music 15 ; both 10 )\n",
            " - Linguistic 80 (ling only 13 ; bibliographic 62 ; music 15 ; both 10 )\n",
            " - Other 3\n",
            "\n",
            "To be included in indexes (based on web portal data layer) 47 ( 21.658986175115206 %)\n",
            " - Bibliographic 47 \n",
            " - Music 5 \n",
            " - Linguistic 6\n",
            "\n",
            "Personas covered in indexes\n",
            " -  Carolina 22.73 %\n",
            " -  David 23.53 %\n",
            " -  Keith 66.67 %\n",
            " -  Keoma 27.27 %\n",
            " -  Mark 31.82 %\n",
            " -  Ortenz 15.91 %\n",
            " -  Patrizia 12.50 %\n",
            " -  Sonia 55.56 %\n",
            " -  William 57.14 %\n",
            "\n",
            "Personas not covered in indexes:\n",
            " - Sethus\n",
            " - Sofia\n",
            " - Anna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehqqw3a6Her9"
      },
      "source": [
        "## High priority entities / properties for Bibliographic CQs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycn_2VXmLAdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf3d5a5-4ac5-49ef-82f1-d38756db2d3f"
      },
      "source": [
        "print(\"\\nEntities/properties covered in indexes\")\n",
        "\n",
        "entities = set(to_include[\"Main \\nentities\"].tolist())\n",
        "entities = list(set([i if ';' not in i else y for i in entities for y in i.split(\"; \") ]))\n",
        "entities_properties = defaultdict(set)\n",
        "for e in entities:\n",
        "  if ':' in e:\n",
        "    entity, properties = e.split(\":\")[0], e.split(\":\")[1].split(\",\")\n",
        "    for p in properties:\n",
        "      entities_properties[entity].add(p)\n",
        "\n",
        "for k,v in entities_properties.items():\n",
        "  print(\"\\n - \",k+\":\", \",\".join(p for p in v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entities/properties covered in indexes\n",
            "\n",
            " -  Instrument:  builder, type, date, place of production, material\n",
            "\n",
            " -  Musical performance:  mediums of performance collection, place, date, all, musical composition, composition, place of production, performer\n",
            "\n",
            " -  Music work:  genre, place of production, date, all, composer, title\n",
            "\n",
            " -  Source:  creator, type, place of production\n",
            "\n",
            " -  Performer:  role, medium of performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDRNdCcIHWCB"
      },
      "source": [
        "## Low priority entities / properties for Bibliographic CQs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq7jmihSXqKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd63ef4-76e7-4c55-df38-dd9d78365054"
      },
      "source": [
        "print(\"\\nEntities/properties to be added ASAP in web portal data layer\")\n",
        "new_entities = set(to_include[\"Additional \\nentities/props\"].tolist())\n",
        "new_entities = list(set([i if ';' not in i else y for i in new_entities for y in i.split(\"; \") ]))\n",
        "relevant_personas = to_include[to_include[\"Additional \\nentities/props\"].str.contains(new_entities[1])]\n",
        "print(\" -\", \",\".join(new_entities), \"\\nRelevant to CQs:\\n -\",\", \".join(relevant_personas[\"CQ ID\"].tolist()))\n",
        "\n",
        "# CQs that cover all bibliographic data but where music/linguistic data are excluded\n",
        "biblio_to_extend = df[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Music \\ndata\"] == 'no') \\\n",
        "            & (df[\"Linguistic data\"] == 'no') \\\n",
        "            & (df[\"Linguistic data\"] == 'no')\\\n",
        "            & (df[\"Include\\nin portal?\"] == 'no')]\n",
        "\n",
        "print(\"\\nTo include all CQs relevant to bibliographic data only (\",len(biblio_to_extend),'- for a total of',len(biblio_to_extend)+len(to_include),'out of',all,'(',(len(biblio_to_extend)+len(to_include))*100/all,'%)), we\\'d need to add')\n",
        "new_entities = set(biblio_to_extend[\"Additional \\nentities/props\"].tolist())\n",
        "new_entities = list(set([i if ';' not in i else y for i in new_entities for y in i.split(\"; \") ]))\n",
        "new_entities_properties = defaultdict(set)\n",
        "for e in new_entities:\n",
        "    entity = e.split(\":\")[0]\n",
        "    properties = e.split(\":\")[1].split(\",\") if ':' in e else e\n",
        "    name = entity if ':' in e else \"_\"+entity\n",
        "    if isinstance(properties,list):\n",
        "      for p in properties:\n",
        "        new_entities_properties[name].add(p)\n",
        "    else:\n",
        "      new_entities_properties[name].add('')\n",
        "for k,v in new_entities_properties.items():\n",
        "  print(\"\\n - \",k+\":\", \",\".join(p for p in v))\n",
        "\n",
        "# all bibliographic data (1) to be included, and (2) not to be included that focus on bibl. data only\n",
        "all_biblio = pd.concat([biblio_to_extend,to_include]).drop_duplicates().reset_index(drop=True)\n",
        "all_biblio_persona = all_biblio.groupby(\"persona\")[\"CQ ID\"].count()\n",
        "df_persona = df.groupby(\"persona\")[\"CQ ID\"].count()\n",
        "personas = pd.merge(all_biblio_persona, df_persona, on=\"persona\")\n",
        "personas.reset_index(level=0, inplace=True)\n",
        "personas[\"percentage\"] = (personas[\"CQ ID_x\"].astype(int)*100/personas[\"CQ ID_y\"].astype(int)).apply(lambda x: f\"{x:.2f}\")\n",
        "personas['_'] = personas[['persona', 'percentage']].apply(tuple, axis=1)\n",
        "\n",
        "print(\"\\nPersonas covered in indexes\")\n",
        "for p,c in personas['_']:\n",
        "  print(\" - \",p,c,\"%\")\n",
        "\n",
        "all_biblio_list = all_biblio_persona.index.tolist()\n",
        "df_list = df_persona.index.tolist()\n",
        "diff = list(set(df_list) - set(all_biblio_list))\n",
        "\n",
        "print(\"\\nPersonas not covered in indexes:\\n -\", \"\\n - \".join(diff))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entities/properties to be added ASAP in web portal data layer\n",
            " - ,_vague \n",
            "Relevant to CQs:\n",
            " - Keith1-CQ1\n",
            "\n",
            "To include all CQs relevant to bibliographic data only ( 40 - for a total of 87 out of 217 ( 40.09216589861751 %)), we'd need to add\n",
            "\n",
            " -  _: \n",
            "\n",
            " -  __vague: \n",
            "\n",
            " -  Musical performance:  hasPerformerSituation, date, building (subproperty of place)\n",
            "\n",
            " -  Performer:  occupation, places, employer, birthplace\n",
            "\n",
            " -  Collection:  composition, all\n",
            "\n",
            " -  Musical work:  lyrics\n",
            "\n",
            " -  Instrument:  current place, chromatic range,  chromatic range\n",
            "\n",
            " -  Source: date\n",
            "\n",
            " -  PerformerSituation:  hasInstrumentOrVoice\n",
            "\n",
            " -  _new property to describe 'kind' of repertoire: \n",
            "\n",
            "Personas covered in indexes\n",
            " -  Carolina 50.00 %\n",
            " -  David 35.29 %\n",
            " -  Keith 66.67 %\n",
            " -  Keoma 72.73 %\n",
            " -  Mark 63.64 %\n",
            " -  Ortenz 27.27 %\n",
            " -  Patrizia 25.00 %\n",
            " -  Sethus 9.68 %\n",
            " -  Sofia 16.00 %\n",
            " -  Sonia 66.67 %\n",
            " -  William 92.86 %\n",
            "\n",
            "Personas not covered in indexes:\n",
            " - Anna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn7d7SwuHlIm"
      },
      "source": [
        "## Low priority entities / properties for mixed CQs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48WdEuyt5XEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e42fa74-79f0-4030-b4bc-cd6088c08834"
      },
      "source": [
        "# CQs covering mixed topics currently set as not to be included\n",
        "biblio_all = df[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Include\\nin portal?\"] == 'no')]\n",
        "biblio_mixed_only = biblio_all[(biblio_all[\"Music \\ndata\"] == 'yes') | (biblio_all[\"Linguistic data\"] == 'yes')]\n",
        "len(biblio_mixed_only)\n",
        "\n",
        "\n",
        "print(\"\\nCQs relevant to mixed topics including bibl. data (\",len(biblio_mixed_only))\n",
        "new_entities = set(biblio_mixed_only[\"Additional \\nentities/props\"].tolist())\n",
        "new_entities = list(set([i if ';' not in i else y for i in new_entities for y in i.split(\"; \") ]))\n",
        "new_entities_properties = defaultdict(set)\n",
        "for e in new_entities:\n",
        "    entity = e.split(\":\")[0]\n",
        "    properties = e.split(\":\")[1].split(\",\") if ':' in e else e\n",
        "    name = entity if ':' in e else \"_\"+entity\n",
        "    if isinstance(properties,list):\n",
        "      for p in properties:\n",
        "        new_entities_properties[name].add(p)\n",
        "    else:\n",
        "      new_entities_properties[name].add('')\n",
        "for k,v in new_entities_properties.items():\n",
        "  print(\"\\n - \",k+\":\", \",\".join(p for p in v))\n",
        "\n",
        "# all bibliographic data (1) to be included, and (2) not to be included that focus on bibl. data only\n",
        "mixed_biblio_persona = biblio_mixed_only.groupby(\"persona\")[\"CQ ID\"].count()\n",
        "df_persona = df.groupby(\"persona\")[\"CQ ID\"].count()\n",
        "personas = pd.merge(mixed_biblio_persona, df_persona, on=\"persona\")\n",
        "personas.reset_index(level=0, inplace=True)\n",
        "personas[\"percentage\"] = (personas[\"CQ ID_x\"].astype(int)*100/personas[\"CQ ID_y\"].astype(int)).apply(lambda x: f\"{x:.2f}\")\n",
        "personas['_'] = personas[['persona', 'percentage']].apply(tuple, axis=1)\n",
        "\n",
        "print(\"\\nPersonas covered in indexes\")\n",
        "for p,c in personas['_']:\n",
        "  print(\" - \",p,c,\"%\")\n",
        "\n",
        "all_biblio_list = mixed_biblio_persona.index.tolist()\n",
        "df_list = df_persona.index.tolist()\n",
        "diff = list(set(df_list) - set(all_biblio_list))\n",
        "\n",
        "print(\"\\nPersonas not covered in indexes:\\n -\", \"\\n - \".join(diff))\n",
        "# count how many are still vague without any main entities\n",
        "print(\"too vague:\")\n",
        "len(biblio_mixed_only[(biblio_mixed_only[\"Main \\nentities\"] == '') & (biblio_mixed_only[\"Additional \\nentities/props\"] == '_vague')] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CQs relevant to mixed topics including bibl. data ( 69\n",
            "\n",
            " -  _: \n",
            "\n",
            " -  __vague: \n",
            "\n",
            " -  Source: hasSubject, hasSubject, date, audience, listener\n",
            "\n",
            " -  Music work:  text, style\n",
            "\n",
            " -  Music feature:  parent work\n",
            "\n",
            " -  Musical performance:  type, hasPerformerSituation, subject of, date, audience, commissioner\n",
            "\n",
            " -  PerformerSituation:   hasInstrumentOrVoice, hasInstrumentOrVoice\n",
            "\n",
            " -  Performer:  relatedTo\n",
            "\n",
            " -  Musical work:  lyrics\n",
            "\n",
            " -  Collection:  composition\n",
            "\n",
            "Personas covered in indexes\n",
            " -  Carolina 40.91 %\n",
            " -  David 23.53 %\n",
            " -  Keoma 18.18 %\n",
            " -  Mark 27.27 %\n",
            " -  Ortenz 65.91 %\n",
            " -  Patrizia 62.50 %\n",
            " -  Sethus 16.13 %\n",
            " -  Sofia 28.00 %\n",
            " -  Sonia 11.11 %\n",
            "\n",
            "Personas not covered in indexes:\n",
            " - Keith\n",
            " - William\n",
            " - Anna\n",
            "too vague:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXwDP6bIHyDa"
      },
      "source": [
        "Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hcg9sHgR_Lqq",
        "outputId": "ec8e42da-bed3-4bb1-c023-1494848b0cec"
      },
      "source": [
        "df['coverage'] = 'none'\n",
        "df.loc[(df[\"Bibl. \\ndata\"] == 'yes') & (df[\"Music \\ndata\"] == 'no') & (df[\"Linguistic data\"] == 'no'), 'coverage'] = 'full' \n",
        "df.loc[(df[\"Bibl. \\ndata\"] == 'yes') & ((df[\"Music \\ndata\"] == 'yes') | (df[\"Linguistic data\"] == 'yes')), 'coverage'] = 'partial'  \n",
        "from google.colab import files\n",
        "df.to_csv('df.csv')\n",
        "files.download('df.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a2d524e5-7647-4603-8d93-6eaa340dc5e7\", \"df.csv\", 39016)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}